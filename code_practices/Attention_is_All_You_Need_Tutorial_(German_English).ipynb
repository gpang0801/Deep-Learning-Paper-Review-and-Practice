{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention is All You Need Tutorial (German-English)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpang0801/Deep-Learning-Paper-Review-and-Practice/blob/main/code_practices/Attention_is_All_You_Need_Tutorial_(German_English).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgnZOimXdN2V"
      },
      "source": [
        "#### **Attention is All You Need (NIPS 2017)** 실습\n",
        "* 본 코드는 기본적으로 **Transformer** 논문의 내용을 최대한 따릅니다.\n",
        "    * 본 논문은 **딥러닝 기반의 자연어 처리** 기법의 기본적인 구성을 이해하고 공부하는 데에 도움을 줍니다.\n",
        "    * 2020년 기준 가장 뛰어난 번역 모델들은 본 논문에서 제안한 **Transformer 기반의 아키텍처**를 따르고 있습니다.\n",
        "* 코드 실행 전에 **[런타임]** → **[런타임 유형 변경]** → 유형을 **GPU**로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPTu1gCK1YXd"
      },
      "source": [
        "#### <b>BLEU Score 계산을 위한 라이브러리 업데이트</b>\n",
        "\n",
        "* <b>[Restart Runtime]</b> 버튼을 눌러 런타임을 재시작할 필요가 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7gjy4bZ1aXc",
        "outputId": "45e14817-0407-44d0-9231-e611cdc898eb"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.6.0 in /usr/local/lib/python3.12/dist-packages (0.6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.32.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.9.0+cu126)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (1.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from torchtext==0.6.0) (0.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torchtext==0.6.0) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->torchtext==0.6.0) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->torchtext==0.6.0) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->torchtext==0.6.0) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_V6NaGYTd62g"
      },
      "source": [
        "#### **데이터 전처리(Preprocessing)**\n",
        "\n",
        "* **spaCy 라이브러리**: 문장의 토큰화(tokenization), 태깅(tagging) 등의 전처리 기능을 위한 라이브러리\n",
        "  * 영어(Engilsh)와 독일어(Deutsch) 전처리 모듈 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbQzI6V1a2m_"
      },
      "source": [
        "%%capture\n",
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfOdc9FSd7xt"
      },
      "source": [
        "import spacy\n",
        "\n",
        "spacy_en = spacy.load(\"en_core_web_sm\") # 영어\n",
        "\n",
        "spacy_de = spacy.load(\"de_core_news_sm\") # 독일어"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eet4iWy_d8s7",
        "outputId": "5bd573a1-a8a1-4cc9-f962-b52795df5ee3"
      },
      "source": [
        "# 간단히 토큰화(tokenization) 기능 써보기\n",
        "\n",
        "tokenized = spacy_en.tokenizer(\"I am a graduate student.\")\n",
        "\n",
        "for i, token in enumerate(tokenized):\n",
        "  print(f\"인덱스 {i}: {token.text}\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "인덱스 0: I\n",
            "인덱스 1: am\n",
            "인덱스 2: a\n",
            "인덱스 3: graduate\n",
            "인덱스 4: student\n",
            "인덱스 5: .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqhzmLvjeFZE"
      },
      "source": [
        "* 영어(English) 및 독일어(Deutsch) **토큰화 함수** 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USWSV869d-s7"
      },
      "source": [
        "# [수정] 토크나이저 함수 자체에서 소문자 처리를 하도록 변경\n",
        "def tokenize_de(text):\n",
        "    return [token.text.lower() for token in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [token.text.lower() for token in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bno5p5l7GRNi",
        "outputId": "9a389a29-4b53-43e2-9fb9-783e2375ee05"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYi1dM7-eH0N"
      },
      "source": [
        "* **필드(field)** 라이브러리를 이용해 데이터셋에 대한 구체적인 전처리 내용을 명시합니다.\n",
        "* Seq2Seq 모델과는 다르게 <b>batch_first 속성의 값을 True로 설정</b>합니다.\n",
        "* 번역 목표\n",
        "    * 소스(SRC): 독일어\n",
        "    * 목표(TRG): 영어"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_dSDRtReGnU"
      },
      "source": [
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SRC = Field(tokenize=tokenize_de, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)\n",
        "\n",
        "TRG = Field(tokenize=tokenize_en, init_token=\"<sos>\", eos_token=\"<eos>\", lower=True, batch_first=True)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX0O1oKQeY2y"
      },
      "source": [
        "* 대표적인 영어-독어 번역 데이터셋인 **Multi30k**를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0J6QuUf5eWfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c3e02a-be52-4100-e494-acec17cb30bc"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# 1. Multi30k 데이터셋 로드 (안정적인 미러 버전)\n",
        "\n",
        "raw_datasets = load_dataset(\"bentrevett/multi30k\")\n",
        "\n",
        "# 2. 데이터 확인 (train, validation, test 분할이 이미 되어 있음)\n",
        "\n",
        "train_dataset = raw_datasets['train']\n",
        "\n",
        "valid_dataset = raw_datasets['validation']\n",
        "\n",
        "test_dataset = raw_datasets['test']\n",
        "\n",
        "# 3. 예시 출력 (독일어 'de', 영어 'en' 쌍)\n",
        "\n",
        "print(f\"첫 번째 데이터: {train_dataset[0]}\")\n",
        "\n",
        "# 결과: {'en': 'Two young, white males are outside near many bushes.', 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 데이터: {'en': 'Two young, White males are outside near many bushes.', 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ-Lhpp0ecOi",
        "outputId": "6dd91abe-a4a2-4c18-bbfe-c8ac5590fbdf"
      },
      "source": [
        "print(f\"학습 데이터셋(training dataset) 크기: {len(train_dataset)}개\")\n",
        "print(f\"평가 데이터셋(validation dataset) 크기: {len(valid_dataset)}개\")\n",
        "print(f\"테스트 데이터셋(testing dataset) 크기: {len(test_dataset)}개\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터셋(training dataset) 크기: 29000개\n",
            "평가 데이터셋(validation dataset) 크기: 1014개\n",
            "테스트 데이터셋(testing dataset) 크기: 1000개\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYghX0SueecT",
        "outputId": "28cbb31e-f3e7-414f-aabb-aa087a42e354"
      },
      "source": [
        "# 30번째 데이터의 독일어(src)와 영어(trg) 출력\n",
        "print(train_dataset[30]['de'])\n",
        "print(train_dataset[30]['en'])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ein Mann, der mit einer Tasse Kaffee an einem Urinal steht.\n",
            "A man standing at a urinal with a coffee cup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekQys1HpegX_"
      },
      "source": [
        "* **필드(field)** 객체의 **build_vocab** 메서드를 이용해 영어와 독어의 단어 사전을 생성합니다.\n",
        "  * **최소 2번 이상** 등장한 단어만을 선택합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4A5ksMyefKy"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# 1. 단어 빈도수 계산용 Counter 생성\n",
        "en_counter = Counter()\n",
        "de_counter = Counter()\n",
        "\n",
        "# 2. 데이터를 돌며 토큰화 및 빈도 측정\n",
        "# train_dataset에서 'de'와 'en' 키를 사용해 데이터를 가져옵니다.\n",
        "for sample in train_dataset:\n",
        "    # Field의 preprocess 함수는 토크나이저를 호출합니다.\n",
        "    de_tokens = SRC.preprocess(sample['de'])\n",
        "    en_tokens = TRG.preprocess(sample['en'])\n",
        "\n",
        "    de_counter.update(de_tokens)\n",
        "    en_counter.update(en_tokens)\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfo21o_5ehmK",
        "outputId": "d364de98-cab6-491a-8b73-7df144dac63d"
      },
      "source": [
        "class SimpleVocab:\n",
        "    def __init__(self, counter, min_freq, specials):\n",
        "        self.freqs = counter\n",
        "        self.itos = specials[:] # ['<unk>', '<pad>', '<sos>', '<eos>']가 들어감\n",
        "\n",
        "        # 1. 빈도수가 min_freq 이상인 단어만 itos 리스트에 추가\n",
        "        for word, freq in counter.items():\n",
        "            if freq >= min_freq and word not in specials:\n",
        "                self.itos.append(word)\n",
        "\n",
        "        # 2. itos 리스트를 바탕으로 stoi(단어 -> 인덱스) 딕셔너리 생성\n",
        "        self.stoi = {word: i for i, word in enumerate(self.itos)}\n",
        "\n",
        "    def __getitem__(self, token):\n",
        "        # 3. 단어를 넣으면 인덱스를 반환. 없으면 <unk>인 0을 반환\n",
        "        return self.stoi.get(token, 0)\n",
        "\n",
        "    def __len__(self):\n",
        "        # 4. 전체 단어장의 크기를 반환\n",
        "        return len(self.itos)\n",
        "\n",
        "# --- 1. 필드에 주입 ---\n",
        "specials = ['<unk>', '<pad>', '<sos>', '<eos>']\n",
        "SRC.vocab = SimpleVocab(de_counter, min_freq=2, specials=specials)\n",
        "TRG.vocab = SimpleVocab(en_counter, min_freq=2, specials=specials)\n",
        "\n",
        "# --- 2. 테스트 코드 실행 ---\n",
        "print(f\"SRC 단어장 크기: {len(SRC.vocab)}\")\n",
        "print(f\"TRG 단어장 크기: {len(TRG.vocab)}\")\n",
        "\n",
        "print(f\"없는 단어 (abcabc) 인덱스: {TRG.vocab['abcabc']}\") # 결과: 0\n",
        "print(f\"패딩 토큰 인덱스: {TRG.vocab['<pad>']}\")            # 결과: 1\n",
        "print(f\"SOS 토큰 인덱스: {TRG.vocab['<sos>']}\")             # 결과: 2\n",
        "print(f\"EOS 토큰 인덱스: {TRG.vocab['<eos>']}\")             # 결과: 3"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC 단어장 크기: 7853\n",
            "TRG 단어장 크기: 5893\n",
            "없는 단어 (abcabc) 인덱스: 0\n",
            "패딩 토큰 인덱스: 1\n",
            "SOS 토큰 인덱스: 2\n",
            "EOS 토큰 인덱스: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHlAcqrGekNm"
      },
      "source": [
        "* 한 문장에 포함된 단어가 순서대로 나열된 상태로 네트워크에 입력되어야 합니다.\n",
        "    * 따라서 하나의 배치에 포함된 문장들이 가지는 단어의 개수가 유사하도록 만들면 좋습니다.\n",
        "    * 이를 위해 BucketIterator를 사용합니다.\n",
        "    * **배치 크기(batch size)**: 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSJQUC0meifi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b182a2-e64e-431a-a63f-bb8a73ac2fc3"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# 1. 문장을 숫자로 바꾸고 패딩을 채워주는 함수 (Collate Function)\n",
        "def collate_fn(batch):\n",
        "    src_batch, trg_batch = [], []\n",
        "    for sample in batch:\n",
        "        # 이미 수정된 tokenize_de/en 이 소문자 처리를 수행함\n",
        "        src_indexes = [2] + [SRC.vocab[token] for token in tokenize_de(sample['de'])] + [3]\n",
        "        trg_indexes = [2] + [TRG.vocab[token] for token in tokenize_en(sample['en'])] + [3]\n",
        "\n",
        "        src_batch.append(torch.tensor(src_indexes))\n",
        "        trg_batch.append(torch.tensor(trg_indexes))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=1, batch_first=True)\n",
        "    trg_batch = pad_sequence(trg_batch, padding_value=1, batch_first=True)\n",
        "    return src_batch, trg_batch\n",
        "\n",
        "# 2. DataLoader 생성\n",
        "BATCH_SIZE = 128\n",
        "train_iterator = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "valid_iterator = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "test_iterator = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "# 3. 데이터 확인 테스트\n",
        "try:\n",
        "    src, trg = next(iter(train_iterator))\n",
        "    print(f\"SRC 배치 크기: {src.shape}\") # [배치 사이즈, 문장 길이]\n",
        "    print(f\"TRG 배치 크기: {trg.shape}\")\n",
        "    print(\"성공적으로 데이터를 불러왔습니다!\")\n",
        "except Exception as e:\n",
        "    print(f\"에러 발생: {e}\")"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC 배치 크기: torch.Size([128, 28])\n",
            "TRG 배치 크기: torch.Size([128, 29])\n",
            "성공적으로 데이터를 불러왔습니다!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4eh7BABetH1",
        "outputId": "95c04a56-b78c-4d15-c7b0-4675386be8b9"
      },
      "source": [
        "# train_iterator에서 첫 번째 배치를 꺼내옵니다.\n",
        "for i, (src, trg) in enumerate(train_iterator):\n",
        "    # src, trg의 모양 확인\n",
        "    # batch_first=True 설정 시: [128, Seq_len]\n",
        "    print(f\"첫 번째 배치 (SRC) 크기: {src.shape}\")\n",
        "    print(f\"첫 번째 배치 (TRG) 크기: {trg.shape}\")\n",
        "\n",
        "    print(\"\\n--- 첫 번째 배치의 0번 문장 토큰 인덱스 ---\")\n",
        "\n",
        "    # batch_first=True인 경우, 첫 번째 차원(0)이 배치, 두 번째 차원(1)이 시퀀스입니다.\n",
        "    # src[0]은 0번 문장 전체를 의미합니다.\n",
        "    target_sentence = src[0]\n",
        "\n",
        "    for j in range(len(target_sentence)): # 문장 길이만큼 반복\n",
        "        token_idx = target_sentence[j].item()\n",
        "        print(f\"시점 {j}: {token_idx}\")\n",
        "\n",
        "        # 패딩 토큰(1)을 만나면 출력을 멈추고 싶다면 아래 주석 해제\n",
        "        # if token_idx == 1: break\n",
        "\n",
        "    # 첫 번째 배치만 확인하고 중단\n",
        "    break"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 배치 (SRC) 크기: torch.Size([128, 30])\n",
            "첫 번째 배치 (TRG) 크기: torch.Size([128, 29])\n",
            "\n",
            "--- 첫 번째 배치의 0번 문장 토큰 인덱스 ---\n",
            "시점 0: 2\n",
            "시점 1: 79\n",
            "시점 2: 120\n",
            "시점 3: 598\n",
            "시점 4: 5394\n",
            "시점 5: 4532\n",
            "시점 6: 16\n",
            "시점 7: 3\n",
            "시점 8: 1\n",
            "시점 9: 1\n",
            "시점 10: 1\n",
            "시점 11: 1\n",
            "시점 12: 1\n",
            "시점 13: 1\n",
            "시점 14: 1\n",
            "시점 15: 1\n",
            "시점 16: 1\n",
            "시점 17: 1\n",
            "시점 18: 1\n",
            "시점 19: 1\n",
            "시점 20: 1\n",
            "시점 21: 1\n",
            "시점 22: 1\n",
            "시점 23: 1\n",
            "시점 24: 1\n",
            "시점 25: 1\n",
            "시점 26: 1\n",
            "시점 27: 1\n",
            "시점 28: 1\n",
            "시점 29: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-HT1C6kfQG6"
      },
      "source": [
        "#### **Multi Head Attention 아키텍처**\n",
        "\n",
        "* 어텐션(attention)은 <b>세 가지 요소</b>를 입력으로 받습니다.\n",
        "    * <b>쿼리(queries)</b>\n",
        "    * <b>키(keys)</b>\n",
        "    * <b>값(values)</b>\n",
        "    * 현재 구현에서는 Query, Key, Value의 차원이 모두 같습니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohBIfgOJiL0a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        assert hidden_dim % n_heads == 0\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hidden_dim // n_heads\n",
        "\n",
        "        self.fc_q = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_k = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_v = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc_o = nn.Linear(hidden_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        # [수정] register_buffer를 사용하여 장치 할당을 자동화하고 연산 속도를 높입니다.\n",
        "        self.register_buffer('scale', torch.sqrt(torch.FloatTensor([self.head_dim])))\n",
        "\n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        batch_size = query.shape[0]\n",
        "\n",
        "        # Q, K, V 생성 -> [batch_size, seq_len, hidden_dim]\n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "\n",
        "        # Head 분할 및 Permute -> [batch_size, n_heads, seq_len, head_dim]\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "\n",
        "        # Attention Energy 계산: (Q * K^T) / scale\n",
        "        # K.permute(0, 1, 3, 2) -> [batch_size, n_heads, head_dim, seq_len]\n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "\n",
        "        # Masking: 마스크 값이 0인(패딩 등) 부분을 매우 작은 값으로 채워 Softmax 결과가 0이 되게 함\n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "        # Attention Score: 각 단어 간의 유사도를 확률 값으로 변환\n",
        "        attention = torch.softmax(energy, dim=-1)\n",
        "\n",
        "        # Scaled Dot-Product Attention: Score와 V를 곱함\n",
        "        x = torch.matmul(self.dropout(attention), V)\n",
        "\n",
        "        # 다시 원래 차원으로 복구 -> [batch_size, seq_len, hidden_dim]\n",
        "        x = x.permute(0, 2, 1, 3).contiguous()\n",
        "        x = x.view(batch_size, -1, self.hidden_dim)\n",
        "\n",
        "        # 최종 Linear Layer\n",
        "        x = self.fc_o(x)\n",
        "\n",
        "        return x, attention"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4-71fGFUQ0P"
      },
      "source": [
        "#### **Position-wise Feedforward 아키텍처**\n",
        "\n",
        "* 입력과 출력의 차원이 동일합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBXPWolrUeYj"
      },
      "source": [
        "class PositionwiseFeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, pf_dim, dropout_ratio):\n",
        "        super().__init__()\n",
        "\n",
        "        self.fc_1 = nn.Linear(hidden_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hidden_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))\n",
        "\n",
        "        # x: [batch_size, seq_len, pf_dim]\n",
        "\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        # x: [batch_size, seq_len, hidden_dim]\n",
        "\n",
        "        return x"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evmxGJCTTF1x"
      },
      "source": [
        "#### **인코더(Encoder) 레이어 아키텍처**\n",
        "\n",
        "* 하나의 인코더 레이어에 대해 정의합니다.\n",
        "    * 입력과 출력의 차원이 같습니다.\n",
        "    * 이러한 특징을 이용해 트랜스포머의 인코더는 인코더 레이어를 여러 번 중첩해 사용합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTPD0jEbe1bx"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 하나의 임베딩이 복제되어 Query, Key, Value로 입력되는 방식\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 필요한 경우 마스크(mask) 행렬을 이용하여 어텐션(attention)할 단어를 조절 가능\n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # position-wise feedforward\n",
        "        _src = self.positionwise_feedforward(src)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RmMSlFXVkxN"
      },
      "source": [
        "#### **인코더(Encoder) 아키텍처**\n",
        "\n",
        "* 전체 인코더 아키텍처를 정의합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **input_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "    * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 <b>위치 임베딩(positional embedding)을 학습</b>하는 형태로 구현합니다.\n",
        "    * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "* &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAd_op0bVhn-"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, src_len]\n",
        "\n",
        "        # 소스 문장의 임베딩과 위치 임베딩을 더한 것을 사용\n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        # 모든 인코더 레이어를 차례대로 거치면서 순전파(forward) 수행\n",
        "        for layer in self.layers:\n",
        "            src = layer(src, src_mask)\n",
        "\n",
        "        # src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        return src # 마지막 레이어의 출력을 반환"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNP2S7g_Xeal"
      },
      "source": [
        "#### **디코더(Decoder) 레이어 아키텍처**\n",
        "\n",
        "* 하나의 디코더 레이어에 대해 정의합니다.\n",
        "    * 입력과 출력의 차원이 같습니다.\n",
        "    * 이러한 특징을 이용해 트랜스포머의 디코더는 디코더 레이어를 여러 번 중첩해 사용합니다.\n",
        "    * 디코더 레이어에서는 두 개의 Multi-Head Attention 레이어가 사용됩니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "* 소스 문장의 &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jn4VCWdXhK5"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hidden_dim, n_heads, pf_dim, dropout_ratio, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hidden_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hidden_dim, n_heads, dropout_ratio, device)\n",
        "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hidden_dim, pf_dim, dropout_ratio)\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "    # 인코더의 출력 값(enc_src)을 어텐션(attention)하는 구조\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        # self attention\n",
        "        # 자기 자신에 대하여 어텐션(attention)\n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # encoder attention\n",
        "        # 디코더의 쿼리(Query)를 이용해 인코더를 어텐션(attention)\n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)\n",
        "\n",
        "        # dropout, residual connection and layer norm\n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        # positionwise feedforward\n",
        "        _trg = self.positionwise_feedforward(trg)\n",
        "\n",
        "        # dropout, residual and layer norm\n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return trg, attention"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK8AWlrcWWRc"
      },
      "source": [
        "#### **디코더(Decoder) 아키텍처**\n",
        "\n",
        "* 전체 디코더 아키텍처를 정의합니다.\n",
        "* 하이퍼 파라미터(hyperparameter)\n",
        "    * **output_dim**: 하나의 단어에 대한 원 핫 인코딩 차원\n",
        "    * **hidden_dim**: 하나의 단어에 대한 임베딩 차원\n",
        "    * **n_layers**: 내부적으로 사용할 인코더 레이어의 개수\n",
        "    * **n_heads**: 헤드(head)의 개수 = scaled dot-product attention의 개수\n",
        "    * **pf_dim**: Feedforward 레이어에서의 내부 임베딩 차원\n",
        "    * **dropout_ratio**: 드롭아웃(dropout) 비율\n",
        "    * **max_length**: 문장 내 최대 단어 개수\n",
        "* 원본 논문과는 다르게 <b>위치 임베딩(positional embedding)을 학습</b>하는 형태로 구현합니다.\n",
        "    * BERT와 같은 모던 트랜스포머 아키텍처에서 사용되는 방식입니다.\n",
        "* Seq2Seq과는 마찬가지로 실제로 추론(inference) 시기에서는 디코더를 반복적으로 넣을 필요가 있습니다.\n",
        "    * 학습(training) 시기에서는 한 번에 출력 문장을 구해 학습할 수 있습니다.\n",
        "* 소스 문장의 &lt;pad&gt; 토큰에 대하여 마스크(mask) 값을 0으로 설정합니다.\n",
        "* 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X64at7IuWQcm"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, n_layers, n_heads, pf_dim, dropout_ratio, device, max_length=100):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hidden_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hidden_dim)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(hidden_dim, n_heads, pf_dim, dropout_ratio, device) for _ in range(n_layers)])\n",
        "\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_ratio)\n",
        "\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hidden_dim])).to(device)\n",
        "\n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "        # trg_mask: [batch_size, trg_len]\n",
        "        # src_mask: [batch_size, src_len]\n",
        "\n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        # pos: [batch_size, trg_len]\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "\n",
        "        for layer in self.layers:\n",
        "            # 소스 마스크와 타겟 마스크 모두 사용\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # trg: [batch_size, trg_len, hidden_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        output = self.fc_out(trg)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b50rQACqW3xX"
      },
      "source": [
        "#### **트랜스포머(Transformer) 아키텍처**\n",
        "\n",
        "* 최종적인 전체 트랜스포머(Transformer) 모델을 정의합니다.\n",
        "* 입력이 들어왔을 때 앞서 정의한 인코더와 디코더를 거쳐 출력 문장을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBGN8VyvW0Et"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.device = device\n",
        "\n",
        "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
        "    def make_src_mask(self, src):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "\n",
        "        return src_mask\n",
        "\n",
        "    # 타겟 문장에서 각 단어는 다음 단어가 무엇인지 알 수 없도록(이전 단어만 보도록) 만들기 위해 마스크를 사용\n",
        "    def make_trg_mask(self, trg):\n",
        "\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 0 0\n",
        "        \"\"\"\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "        # trg_pad_mask: [batch_size, 1, 1, trg_len]\n",
        "\n",
        "        trg_len = trg.shape[1]\n",
        "\n",
        "        \"\"\" (마스크 예시)\n",
        "        1 0 0 0 0\n",
        "        1 1 0 0 0\n",
        "        1 1 1 0 0\n",
        "        1 1 1 1 0\n",
        "        1 1 1 1 1\n",
        "        \"\"\"\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
        "\n",
        "        # trg_sub_mask: [trg_len, trg_len]\n",
        "\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "\n",
        "        # src: [batch_size, src_len]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "\n",
        "        # src_mask: [batch_size, 1, 1, src_len]\n",
        "        # trg_mask: [batch_size, 1, trg_len, trg_len]\n",
        "\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "\n",
        "        # enc_src: [batch_size, src_len, hidden_dim]\n",
        "\n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # output: [batch_size, trg_len, output_dim]\n",
        "        # attention: [batch_size, n_heads, trg_len, src_len]\n",
        "\n",
        "        return output, attention"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnBKjEFFqHrV"
      },
      "source": [
        "#### **학습(Training)**\n",
        "\n",
        "* 하이퍼 파라미터 설정 및 모델 초기화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJG6xhUaXZ32"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "HIDDEN_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 8\n",
        "DEC_HEADS = 8\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVgG8VOYXbIk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5968c08d-3fa5-41bc-9dea-ebba8e0053d1"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"현재 사용 중인 장치: {device}\")\n",
        "\n",
        "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
        "\n",
        "# 인코더(encoder)와 디코더(decoder) 객체 선언\n",
        "enc = Encoder(INPUT_DIM, HIDDEN_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HIDDEN_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "# Transformer 객체 선언\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 사용 중인 장치: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B1BkZkUqQjo"
      },
      "source": [
        "* **모델 가중치 파라미터 초기화**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnCu5WAyXmes",
        "outputId": "1dc96875-1291-4b80-f3b5-5b334bb37324"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 9,038,341 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEY3bppUXndU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffafba95-5c07-4a8f-e66d-9811a6f6a704"
      },
      "source": [
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "\n",
        "model.apply(initialize_weights)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (tok_embedding): Embedding(7853, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x EncoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (tok_embedding): Embedding(5893, 256)\n",
              "    (pos_embedding): Embedding(100, 256)\n",
              "    (layers): ModuleList(\n",
              "      (0-2): 3 x DecoderLayer(\n",
              "        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (enc_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (ff_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "        (self_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (encoder_attention): MultiHeadAttentionLayer(\n",
              "          (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (fc_o): Linear(in_features=256, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
              "          (fc_1): Linear(in_features=256, out_features=512, bias=True)\n",
              "          (fc_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (fc_out): Linear(in_features=256, out_features=5893, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsdTndLDqWQf"
      },
      "source": [
        "* 학습 및 평가 함수 정의\n",
        "    * 기본적인 Seq2Seq 모델과 거의 유사하게 작성할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6-92JSlXrwM"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Adam optimizer로 학습 최적화\n",
        "LEARNING_RATE = 0.0005\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 뒷 부분의 패딩(padding)에 대해서는 값 무시\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcIltwlRXssU"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for src, trg in iterator: # [수정] batch.src 대신 직접 언패킹\n",
        "        src = src.to(device)\n",
        "        trg = trg.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # [수정] batch_first=True 설정에 맞게 슬라이싱 (뒤의 1열 제외)\n",
        "        output, _ = model(src, trg[:, :-1])\n",
        "\n",
        "        # output: [batch_size, trg_len - 1, output_dim]\n",
        "        # trg: [batch_size, trg_len]\n",
        "\n",
        "        output_dim = output.shape[-1]\n",
        "\n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:, 1:].contiguous().view(-1) # <sos> 제외\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69a5vBggXt4M"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, trg in iterator: # [수정] 직접 언패킹\n",
        "            src = src.to(device)\n",
        "            trg = trg.to(device)\n",
        "\n",
        "            output, _ = model(src, trg[:, :-1])\n",
        "\n",
        "            output_dim = output.shape[-1]\n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdmhWLNcs76v"
      },
      "source": [
        "* 학습(training) 및 검증(validation) 진행\n",
        "    * **학습 횟수(epoch)**: 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPjtaQ6CXvGk"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTe-5FdvXwdE",
        "outputId": "4f6afa61-9c25-486d-eccc-3870c9ec75c5"
      },
      "source": [
        "import time\n",
        "import math\n",
        "import random\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    start_time = time.time() # 시작 시간 기록\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time() # 종료 시간 기록\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'transformer_german_to_english.pt')\n",
        "\n",
        "    print(f'Epoch: {epoch + 1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):.3f}')\n",
        "    print(f'\\tValidation Loss: {valid_loss:.3f} | Validation PPL: {math.exp(valid_loss):.3f}')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Time: 0m 15s\n",
            "\tTrain Loss: 4.234 | Train PPL: 69.019\n",
            "\tValidation Loss: 3.094 | Validation PPL: 22.061\n",
            "Epoch: 02 | Time: 0m 17s\n",
            "\tTrain Loss: 2.807 | Train PPL: 16.555\n",
            "\tValidation Loss: 2.349 | Validation PPL: 10.477\n",
            "Epoch: 03 | Time: 0m 16s\n",
            "\tTrain Loss: 2.224 | Train PPL: 9.241\n",
            "\tValidation Loss: 2.012 | Validation PPL: 7.477\n",
            "Epoch: 04 | Time: 0m 16s\n",
            "\tTrain Loss: 1.870 | Train PPL: 6.489\n",
            "\tValidation Loss: 1.840 | Validation PPL: 6.296\n",
            "Epoch: 05 | Time: 0m 16s\n",
            "\tTrain Loss: 1.629 | Train PPL: 5.100\n",
            "\tValidation Loss: 1.754 | Validation PPL: 5.779\n",
            "Epoch: 06 | Time: 0m 16s\n",
            "\tTrain Loss: 1.440 | Train PPL: 4.220\n",
            "\tValidation Loss: 1.696 | Validation PPL: 5.452\n",
            "Epoch: 07 | Time: 0m 16s\n",
            "\tTrain Loss: 1.288 | Train PPL: 3.627\n",
            "\tValidation Loss: 1.665 | Validation PPL: 5.284\n",
            "Epoch: 08 | Time: 0m 16s\n",
            "\tTrain Loss: 1.160 | Train PPL: 3.190\n",
            "\tValidation Loss: 1.665 | Validation PPL: 5.285\n",
            "Epoch: 09 | Time: 0m 16s\n",
            "\tTrain Loss: 1.051 | Train PPL: 2.861\n",
            "\tValidation Loss: 1.685 | Validation PPL: 5.391\n",
            "Epoch: 10 | Time: 0m 16s\n",
            "\tTrain Loss: 0.960 | Train PPL: 2.613\n",
            "\tValidation Loss: 1.703 | Validation PPL: 5.492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "W1oT2_2yYCBM",
        "outputId": "c931d229-a109-44e0-927a-db333bd66b0e"
      },
      "source": [
        "# 학습된 모델 저장\n",
        "from google.colab import files\n",
        "\n",
        "files.download('transformer_german_to_english.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2ec1dc00-ee38-4c41-9e36-b4af82059c27\", \"transformer_german_to_english.pt\", 36208001)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvW5ZDUwwJaI"
      },
      "source": [
        "#### **모델 최종 테스트(testing) 결과 확인**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlO_lLD3wJx0",
        "outputId": "f7eed582-cc9a-48d6-e644-d122c777ab1c"
      },
      "source": [
        "!wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EbWFiKBmscFBrbzCQxRyqwsBwcXgdKdimkdsBl2dE9VYaQ?download=1 -O transformer_german_to_english.pt"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2026-01-04 11:55:30--  https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EbWFiKBmscFBrbzCQxRyqwsBwcXgdKdimkdsBl2dE9VYaQ?download=1\n",
            "Resolving postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to postechackr-my.sharepoint.com (postechackr-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/dongbinna_postech_ac_kr/Documents/Research/models/transformer_german_to_english.pt?ga=1 [following]\n",
            "--2026-01-04 11:55:31--  https://postechackr-my.sharepoint.com/personal/dongbinna_postech_ac_kr/Documents/Research/models/transformer_german_to_english.pt?ga=1\n",
            "Reusing existing connection to postechackr-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36208001 (35M) [application/octet-stream]\n",
            "Saving to: ‘transformer_german_to_english.pt’\n",
            "\n",
            "transformer_german_ 100%[===================>]  34.53M  8.50MB/s    in 5.0s    \n",
            "\n",
            "2026-01-04 11:55:37 (6.91 MB/s) - ‘transformer_german_to_english.pt’ saved [36208001/36208001]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sScSSNYbwKPR",
        "outputId": "d9717d8d-1788-4582-843a-2022c48f1bac"
      },
      "source": [
        "\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):.3f}')"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.753 | Test PPL: 5.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIE5KXd5wVUf"
      },
      "source": [
        "#### **나만의 데이터로 모델 사용해보기**\n",
        "\n",
        "* 테스트 데이터셋을 이용해 모델 테스트 진행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plUPXH4UYKEU"
      },
      "source": [
        "def translate_sentence(sentence, src_vocab, trg_vocab, model, device, max_len=50):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. 입력 문장 토큰화\n",
        "    if isinstance(sentence, str):\n",
        "        tokens = tokenize_de(sentence)\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # 2. 특수 토큰 부착 및 정수 인코딩\n",
        "    tokens = ['<sos>'] + tokens + ['<eos>']\n",
        "    # src_vocab[token]은 SimpleVocab의 __getitem__을 호출하여 인덱스를 가져옵니다.\n",
        "    src_indexes = [src_vocab[token] for token in tokens]\n",
        "\n",
        "    # 3. 텐서 변환 [1, Seq_Len]\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
        "\n",
        "    # 4. 소스 마스크 생성\n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "\n",
        "    # 5. 인코더 통과\n",
        "    with torch.no_grad():\n",
        "        enc_src = model.encoder(src_tensor, src_mask)\n",
        "\n",
        "    # 6. 디코더 단어 생성 시작 (<sos> 인덱스 가져오기)\n",
        "    trg_indexes = [trg_vocab['<sos>']]\n",
        "\n",
        "    for i in range(max_len):\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)\n",
        "\n",
        "        # 마지막 시점의 단어 확률이 가장 높은 인덱스 선택\n",
        "        pred_token = output.argmax(2)[:, -1].item()\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        # <eos>를 만나면 생성 중단\n",
        "        if pred_token == trg_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "    # 7. 인덱스를 실제 단어로 변환\n",
        "    trg_tokens = [trg_vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    # <sos> 토큰 제외하고 반환\n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZZufujhxNuO",
        "outputId": "3931e905-8dd3-4ee7-f0c1-ec755fa80703"
      },
      "source": [
        "example_idx = 10\n",
        "\n",
        "# 1. 데이터 가져오기\n",
        "sample = test_dataset[example_idx]\n",
        "src = sample['de'] # \"Eine Mutter...\" (문자열)\n",
        "trg = sample['en']\n",
        "\n",
        "print(f'소스 문장 (DE): {src}')\n",
        "print(f'타겟 문장 (EN): {trg}')\n",
        "\n",
        "# 2. [수정 포인트] src.vocab 대신 실제 단어장 변수인 SRC_vocab, TRG_vocab 전달\n",
        "# 만약 SRC_vocab 변수가 없다면 SRC.vocab (대문자 SRC 필드 객체)을 사용하세요.\n",
        "translation, attention = translate_sentence(src, SRC_vocab, TRG_vocab, model, device)\n",
        "\n",
        "# 3. 결과 출력 (<eos> 토큰 정리)\n",
        "if '<eos>' in translation:\n",
        "    translation = translation[:translation.index('<eos>')]\n",
        "\n",
        "print(\"\\n모델 번역 결과:\", \" \".join(translation))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "소스 문장 (DE): Eine Mutter und ihr kleiner Sohn genießen einen schönen Tag im Freien.\n",
            "타겟 문장 (EN): A mother and her young song enjoying a beautiful day outside.\n",
            "\n",
            "모델 번역 결과: a mother and her son enjoy a beautiful day outside .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnRoAAEjyckb"
      },
      "source": [
        "* 어텐션 맵(Attention Map) 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lNAb_YKYLmU"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention, n_heads=8, n_rows=4, n_cols=2):\n",
        "\n",
        "    assert n_rows * n_cols == n_heads\n",
        "\n",
        "    # 출력할 그림 크기 조절\n",
        "    fig = plt.figure(figsize=(15, 25))\n",
        "\n",
        "    for i in range(n_heads):\n",
        "        ax = fig.add_subplot(n_rows, n_cols, i + 1)\n",
        "\n",
        "        # 어텐션(Attention) 스코어 확률 값을 이용해 그리기\n",
        "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
        "\n",
        "        cax = ax.matshow(_attention, cmap='bone')\n",
        "\n",
        "        ax.tick_params(labelsize=12)\n",
        "        ax.set_xticklabels([''] + ['<sos>'] + [t.lower() for t in sentence] + ['<eos>'], rotation=45)\n",
        "        ax.set_yticklabels([''] + translation)\n",
        "\n",
        "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnCvQ5d8YMrj",
        "outputId": "41778500-eb47-49b4-afc0-a9fbc7f1662e"
      },
      "source": [
        "# 1. 기존에 만든 SRC.vocab을 SRC_vocab이라는 이름으로도 사용할 수 있게 할당합니다.\n",
        "SRC_vocab = SRC.vocab\n",
        "TRG_vocab = TRG.vocab\n",
        "\n",
        "# 2. 확인 출력\n",
        "print(f\"SRC_vocab 변수 등록 완료 (크기: {len(SRC_vocab)})\")\n",
        "print(f\"TRG_vocab 변수 등록 완료 (크기: {len(TRG_vocab)})\")\n",
        "\n",
        "# 3. 이제 다시 번역 테스트 코드를 실행해 보세요!\n",
        "example_idx = 10\n",
        "\n",
        "sample = test_dataset[example_idx]\n",
        "src = sample['de']\n",
        "trg = sample['en']\n",
        "\n",
        "print(f'\\n소스 문장 (DE): {src}')\n",
        "print(f'타겟 문장 (EN): {trg}')\n",
        "\n",
        "# 이제 SRC_vocab을 찾아내어 에러 없이 실행될 것입니다.\n",
        "translation, attention = translate_sentence(src, SRC_vocab, TRG_vocab, model, device, logging=True)\n",
        "\n",
        "# <eos> 이후는 출력하지 않도록 정리\n",
        "if '<eos>' in translation:\n",
        "    translation = translation[:translation.index('<eos>')]\n",
        "\n",
        "print(\"\\n모델 번역 결과:\", \" \".join(translation))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC_vocab 변수 등록 완료 (크기: 7853)\n",
            "TRG_vocab 변수 등록 완료 (크기: 5893)\n",
            "\n",
            "소스 문장 (DE): Eine Mutter und ihr kleiner Sohn genießen einen schönen Tag im Freien.\n",
            "타겟 문장 (EN): A mother and her young song enjoying a beautiful day outside.\n",
            "\n",
            "모델 번역 결과: setting playground stove courtyard are outside girls white multicolored many two <unk> near <unk> , white sniffs near attire white sniffs operating white puddle , white fountain young\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "id": "glUG8EnJYPGc",
        "outputId": "bc92da9b-458b-43e7-da63-1ecf71e7628e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "def display_attention(sentence, translation, attention):\n",
        "    # 그래프 크기 설정\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "    # 어텐션 데이터 (일반적으로 마지막 레이어의 어텐션을 시각화)\n",
        "    # attention shape: [n_heads, trg_len, src_len]\n",
        "    # 여기서는 첫 번째 헤드의 어텐션만 가져와서 시각화합니다.\n",
        "    attention = attention.squeeze(0)[0].cpu().detach().numpy()\n",
        "\n",
        "    # 행렬 시각화\n",
        "    cax = ax.matshow(attention, cmap='bone')\n",
        "\n",
        "    # 축 설정\n",
        "    ax.tick_params(labelsize=12)\n",
        "\n",
        "    # 소스 문장(독일어)을 x축에, 결과 문장(영어)을 y축에 배치\n",
        "    # 입력 문장이 문자열인 경우 토큰화 진행\n",
        "    if isinstance(sentence, str):\n",
        "        src_tokens = ['<sos>'] + tokenize_de(sentence) + ['<eos>']\n",
        "    else:\n",
        "        src_tokens = ['<sos>'] + [token.lower() for token in sentence] + ['<eos>']\n",
        "\n",
        "    ax.set_xticklabels([''] + src_tokens, rotation=45)\n",
        "    ax.set_yticklabels([''] + translation)\n",
        "\n",
        "    # 틱 간격 설정\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "display_attention(src, translation, attention)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2392250698.py:27: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + src_tokens, rotation=45)\n",
            "/tmp/ipython-input-2392250698.py:28: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + translation)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t07uJBHB0Voo"
      },
      "source": [
        "#### <b>BLEU Score 계산</b>\n",
        "\n",
        "* 학습된 트랜스포머(Transformer) 모델의 BLEU 스코어 계산"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7hsjkOKb3HS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167c9d9d-2167-49bb-ff05-ecffa914ba54"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\n",
        "\n",
        "def calculate_bleu_fixed(data, src_vocab, trg_vocab, model, device, max_len=50):\n",
        "    trgs = []\n",
        "    pred_trgs = []\n",
        "\n",
        "    # 슬라이싱된 데이터가 딕셔너리 형태일 경우를 위해 길이를 측정합니다.\n",
        "    num_samples = len(data['de']) if isinstance(data, dict) and 'de' in data else len(data)\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # 데이터가 딕셔너리(슬라이싱 결과)인지 개별 샘플 리스트인지 판별하여 접근\n",
        "        if isinstance(data, dict):\n",
        "            src = data['de'][i]\n",
        "            trg = data['en'][i]\n",
        "        else:\n",
        "            src = data[i]['de']\n",
        "            trg = data[i]['en']\n",
        "\n",
        "        # 모델을 통해 번역 수행\n",
        "        prediction, _ = translate_sentence(src, src_vocab, trg_vocab, model, device, max_len)\n",
        "\n",
        "        # <eos> 토큰 제거 (itos에 따른 처리)\n",
        "        if '<eos>' in prediction:\n",
        "            prediction = prediction[:prediction.index('<eos>')]\n",
        "\n",
        "        pred_trgs.append(prediction)\n",
        "\n",
        "        # 정답 문장 토큰화 (리스트의 리스트 형태)\n",
        "        trgs.append([tokenize_en(trg)])\n",
        "\n",
        "    # BLEU 점수 계산\n",
        "    score = bleu_score(pred_trgs, trgs)\n",
        "    return score\n",
        "\n",
        "# 실행 (test_dataset[:100] 슬라이싱을 그대로 사용해도 이제 안전합니다)\n",
        "bleu_result = calculate_bleu_fixed(test_dataset[:100], SRC_vocab, TRG_vocab, model, device)\n",
        "print(f'나의 모델 BLEU 점수: {bleu_result * 100:.2f}')"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "나의 모델 BLEU 점수: 36.62\n"
          ]
        }
      ]
    }
  ]
}